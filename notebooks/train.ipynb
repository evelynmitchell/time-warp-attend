{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import twa\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from twa.utils import ensure_dir, write_yaml\n",
    "from twa.data.ode import FlowSystemODE\n",
    "import random\n",
    "from twa.train import VecTopoDataset, train_model_alt, predict_model\n",
    "\n",
    "random.seed(2)\n",
    "torch.manual_seed(2)\n",
    "\n",
    "torch.use_deterministic_algorithms(True) \n",
    "%set_env CUBLAS_WORKSPACE_CONFIG=:4096:8\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "num_lattice = 64"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classify point vs cycle attractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training configuration\n",
    "outdir = '../output/'\n",
    "data_dir = os.path.join(outdir, 'data') \n",
    "dim = 2\n",
    "batch_size = 64\n",
    "\n",
    "train_data_descs = ['simple_oscillator_nsfcl']\n",
    "\n",
    "train_data_desc_ = '_'.join(train_data_descs)\n",
    "\n",
    "kwargs_train = {}\n",
    "\n",
    "with_attention = False # True \n",
    "datatype = 'angle'\n",
    "model_type = None\n",
    "\n",
    "save = False; save_dir = None\n",
    "\n",
    "with_attention_str = 'atten' if with_attention else 'noatten'\n",
    "if model_type is None:\n",
    "    exp_desc = train_data_desc_ + '_' + datatype + '_' + with_attention_str\n",
    "else:\n",
    "    exp_desc = train_data_desc_ + '_' + datatype + '_' + model_type\n",
    "\n",
    "datasize = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine train datasets in case multiple are given\n",
    "for itrain_data_desc, train_data_desc in enumerate(train_data_descs):\n",
    "    train_data_dir = os.path.join(data_dir, train_data_desc)\n",
    "    if itrain_data_desc == 0:\n",
    "        train_dataset = VecTopoDataset(train_data_dir, datatype=datatype, datasize=datasize, filter_outbound=True)\n",
    "        train_dataset.plot_data()\n",
    "    else:\n",
    "        train_dataset += VecTopoDataset(train_data_dir, datatype=datatype, datasize=datasize, filter_outbound=True)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "model, losses = train_model_alt(train_dataset, model_type=model_type, with_attention=with_attention, device=device, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot train loss\n",
    "plt.plot(losses)\n",
    "plt.xlabel('iteration')\n",
    "plt.ylabel('loss')\n",
    "plt.title(exp_desc)\n",
    "plt.ylim(0, 1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize train results\n",
    "# plot examples of attention masks\n",
    "model.plot_attention(train_dataset, n_samples=9)\n",
    "\n",
    "\n",
    "correct, auc, output = predict_model(model, train_dataset)\n",
    "fig, ax = plt.subplots(1,2, figsize=(15,5))\n",
    "sysp = train_dataset.sysp\n",
    "\n",
    "twa.utils.plot_diverge_scale(sysp[:,0], sysp[:,1], output[:,0], ax=ax[0], title='pt logit')\n",
    "twa.utils.plot_diverge_scale(sysp[:,0], sysp[:,1], output[:,1], ax=ax[1], title='cycle logit')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examine test data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "results_dir = os.path.join(outdir, 'results')\n",
    "# save = True; save_dir = None\n",
    "exp_results_dir = os.path.join(results_dir, exp_desc)\n",
    "ensure_dir(exp_results_dir)\n",
    "\n",
    "test_data_descs = [\n",
    "    'simple_oscillator_noaug',\n",
    "    'simple_oscillator_nsfcl',\n",
    "    'suphopf',\n",
    "    'lienard_poly',\n",
    "    'lienard_sigmoid',\n",
    "    'vanderpol',\n",
    "    'bzreaction',\n",
    "    'selkov',\n",
    "    'selkov2',\n",
    "    'repressilator',\n",
    "    'pancreas_clusters_random_bin',\n",
    "]\n",
    "\n",
    "\n",
    "tt = 'test'\n",
    "res = []\n",
    "for test_data_desc in test_data_descs:\n",
    "    print(test_data_desc)\n",
    "    test_data_dir = os.path.join(data_dir, test_data_desc)\n",
    "    if os.path.isdir(test_data_dir):\n",
    "        test_dataset = VecTopoDataset(test_data_dir,  tt=tt, datatype=datatype) \n",
    "\n",
    "        if save:\n",
    "            save_dir = os.path.join(exp_results_dir, test_data_desc)\n",
    "            ensure_dir(save_dir)\n",
    "\n",
    "        correct, auc, _ = predict_model(model, test_dataset, verbose=False, save=save, save_dir=save_dir)\n",
    "        res.append({'data': os.path.basename(test_data_dir),\n",
    "                    'correct': correct,\n",
    "                    'auc': auc})\n",
    "\n",
    "pd.DataFrame(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_dir = os.path.join(os.path.join(outdir, 'data'), 'selkov')\n",
    "test_dataset = VecTopoDataset(test_data_dir,  tt=tt, datatype=datatype) \n",
    "correct, auc, _ = predict_model(model, test_dataset, verbose=False, save=save, save_dir=save_dir)\n",
    "print(correct, auc)\n",
    "\n",
    "test_data_dir = os.path.join(os.path.join(outdir, 'dataprev'), 'selkov_new')\n",
    "test_dataset = VecTopoDataset(test_data_dir,  tt=tt, datatype=datatype) \n",
    "correct, auc, _ = predict_model(model, test_dataset, verbose=False, save=save, save_dir=save_dir)\n",
    "print(correct, auc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_desc = 'selkov2'\n",
    "test_data_dir = os.path.join(data_dir, test_data_desc)\n",
    "test_dataset = VecTopoDataset(test_data_dir,  tt=tt, datatype=datatype) \n",
    "\n",
    "model.plot_attention(test_dataset, n_samples=9)\n",
    "plt.show()\n",
    "\n",
    "correct, auc, output = predict_model(model, test_dataset)\n",
    "fig, ax = plt.subplots(1,4, figsize=(20,5))\n",
    "sysp = test_dataset.sysp\n",
    "idx0 = twa.dt.Selkov.plot_param_idx[0]\n",
    "idx1 = twa.dt.Selkov.plot_param_idx[1]\n",
    "ax[0].scatter(sysp[:,idx0], sysp[:,idx1], c=test_dataset.label[:,0])\n",
    "ax[1].scatter(sysp[:,idx0], sysp[:,idx1], c=output[:,0] > 0)\n",
    "ax[1].scatter(sysp[:,idx0], sysp[:,idx1], c=output[:,0] > 0)\n",
    "twa.utils.plot_diverge_scale(sysp[:,idx0], sysp[:,idx1], output[:,0], ax=ax[2], title='pt logit')\n",
    "twa.utils.plot_diverge_scale(sysp[:,idx0], sysp[:,idx1], output[:,1], ax=ax[3], title='cycle logit')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test with noise\n",
    "tt = 'test'\n",
    "noise = 0.5\n",
    "test_data_dir = os.path.join(data_dir, train_data_desc_)\n",
    "test_data_desc = train_data_desc_ + '_noise%.2f' % noise\n",
    "test_dataset = VecTopoDataset(test_data_dir,  tt=tt, datatype=datatype, noise=noise) \n",
    "\n",
    "if save:\n",
    "    save_dir = os.path.join(exp_results_dir, test_data_desc)\n",
    "    ensure_dir(save_dir)\n",
    "\n",
    "correct, auc, _ = predict_model(model, test_dataset, verbose=False, save=save, save_dir=save_dir)\n",
    "print(f'{train_data_desc_}, with Gaussian noise of scale {noise}, {correct:.2f} correct, {auc:.2f} auc')\n",
    "\n",
    "test_dataset.plot_data()\n",
    "\n",
    "tt = 'test'\n",
    "mask_prob = 0.25\n",
    "test_data_desc = train_data_desc_ + '_masked%.2f' % mask_prob\n",
    "test_dataset = VecTopoDataset(test_data_dir,  tt=tt, datatype=datatype, mask_prob=mask_prob) \n",
    "\n",
    "if save:\n",
    "    save_dir = os.path.join(exp_results_dir, test_data_desc)\n",
    "    ensure_dir(save_dir)\n",
    "\n",
    "correct, auc, _ = predict_model(model, test_dataset, verbose=False, save=save, save_dir=save_dir)\n",
    "res.append({'data': os.path.basename(test_data_dir),\n",
    "            'correct': correct,\n",
    "            'auc': auc})\n",
    "\n",
    "test_dataset.plot_data()\n",
    "print(f'{train_data_desc_}, with mask probability {mask_prob}, {correct:.2f} correct, {auc:.2f} auc')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if save:\n",
    "    models_dir = os.path.join(outdir, 'models')\n",
    "    exp_models_dir = os.path.join(models_dir, exp_desc)\n",
    "    ensure_dir(exp_models_dir)\n",
    "\n",
    "    torch.save(model.state_dict(), os.path.join(exp_models_dir, 'model.pt'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p2vd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
